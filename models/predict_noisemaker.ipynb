{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: During startup - \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: Warning message:\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: Setting LC_CTYPE failed, using \"C\" \n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import csv   \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import librosa as lr\n",
    "import librosa.display as lrd\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS-noisemaker-2018-01-10_03:45.csv\n"
     ]
    }
   ],
   "source": [
    "SPLIT_TRAIN_TEST = .8\n",
    "TARGET_FILE = '../data/noisemaker/noisemaker.csv'\n",
    "SAMPLES_FOLDER = '../data/noisemaker/noisemaker_samples/'\n",
    "FOLDER_PREFIX = 'noisemaker'\n",
    "\n",
    "D = str(datetime.datetime.now())\n",
    "RESULTS_FILE = 'RESULTS-' + FOLDER_PREFIX + '-' + D[:16].replace(' ','_') + '.csv'\n",
    "print RESULTS_FILE\n",
    "\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "N_MFCC = 20\n",
    "N_MEL = 32\n",
    "\n",
    "SUBSET = False\n",
    "N_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 1\n",
    "VALIDATION = .1\n",
    "\n",
    "DEPENDENCIES = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepares datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   filter_sustain  amp_sustain  lfo1_amount  osc1_pulse_width  amp_decay  \\\n",
      "0        0.629921     1.811024     2.755906          6.377953   1.653543   \n",
      "1        9.291339     5.748031     0.314961          5.039370   9.212598   \n",
      "2        7.086614     3.779528     9.921260          2.204724   6.141732   \n",
      "3        0.314961     6.141732     8.425197          1.181102   7.007874   \n",
      "4        3.622047     7.165354     5.748031          7.165354   3.464567   \n",
      "\n",
      "   lfo1_rate  filter_cutoff lfo1_destination osc2_wave  osc2_volume  \\\n",
      "0   8.818898       1.496063           FILTER      Sine     3.464567   \n",
      "1   0.078740       4.803150        OSC1PITCH      Sine     9.763780   \n",
      "2   4.015748       2.440945          NOTHING      Sine     7.086614   \n",
      "3   7.244094       2.204724          NOTHING     Noise     9.606299   \n",
      "4   2.834646       0.472441          NOTHING  Triangle     1.653543   \n",
      "\n",
      "   amp_attack  osc1_volume  filter_resonance  filter_attack  filter_decay  \\\n",
      "0    5.590551     8.346457          5.118110       2.125984      4.251969   \n",
      "1    7.322835     4.960630          1.653543       4.960630      4.251969   \n",
      "2    2.913386     0.000000          5.275591       8.031496      0.314961   \n",
      "3    4.566929     9.370079          7.086614       4.251969      3.228346   \n",
      "4    5.196850     3.700787          7.007874       6.456693      9.921260   \n",
      "\n",
      "  osc1_wave    file  \n",
      "0     Pulse  s0.wav  \n",
      "1       Saw  s1.wav  \n",
      "2     Pulse  s2.wav  \n",
      "3     Noise  s3.wav  \n",
      "4     Pulse  s4.wav  \n",
      "8000 2000\n",
      "\n",
      "Training data: (8000, 17)\n",
      "Test data: (2000, 17)\n",
      "\n",
      "0    s0.wav\n",
      "1    s1.wav\n",
      "2    s2.wav\n",
      "3    s3.wav\n",
      "4    s4.wav\n",
      "Name: file, dtype: object\n",
      "8000    s8000.wav\n",
      "8001    s8001.wav\n",
      "8002    s8002.wav\n",
      "8003    s8003.wav\n",
      "8004    s8004.wav\n",
      "Name: file, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Prepares labels\n",
    "Y = pd.read_csv(TARGET_FILE)\n",
    "if SUBSET:\n",
    "    Y = Y.head(100)\n",
    "print Y.head()\n",
    "\n",
    "len_train = int(Y.shape[0]*.8)\n",
    "len_test = int(Y.shape[0]*.2)\n",
    "print len_train, len_test\n",
    "\n",
    "Y_train = Y.iloc[:len_train,:]\n",
    "Y_test = Y.iloc[len_train:,:]\n",
    "print \n",
    "print 'Training data:', Y_train.shape\n",
    "print 'Test data:', Y_test.shape\n",
    "\n",
    "Y_train, files_train =  Y_train.drop('file', axis=1), Y_train['file']\n",
    "Y_test, files_test = Y_test.drop('file', axis=1), Y_test['file']\n",
    "print\n",
    "print files_train[:5]\n",
    "print files_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate: 22050\n",
      "Loaded testing waveform #0\n",
      "Loaded testing waveform #100\n",
      "Loaded testing waveform #200\n",
      "Loaded testing waveform #300\n",
      "Loaded testing waveform #400\n",
      "Loaded testing waveform #500\n",
      "Loaded testing waveform #600\n",
      "Loaded testing waveform #700\n",
      "Loaded testing waveform #800\n",
      "Loaded testing waveform #900\n",
      "Loaded testing waveform #1000\n",
      "Loaded testing waveform #1100\n",
      "Loaded testing waveform #1200\n",
      "Loaded testing waveform #1300\n",
      "Loaded testing waveform #1400\n",
      "Loaded testing waveform #1500\n",
      "Loaded testing waveform #1600\n",
      "Loaded testing waveform #1700\n",
      "Loaded testing waveform #1800\n",
      "Loaded testing waveform #1900\n",
      "(2000, 19845)\n",
      "Loaded training waveform #0\n",
      "Loaded training waveform #100\n",
      "Loaded training waveform #200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a8e1b53f5e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'Loaded training waveform #'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAMPLES_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mwaveforms_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveforms_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/librosa/core/audio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/librosa/core/audio.pyc\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/resampy/core.pyc\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresample_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loads waveforms\n",
    "sampling_rate = lr.load(SAMPLES_FOLDER + files_train[0])[1]\n",
    "print 'Sampling rate:', sampling_rate\n",
    "\n",
    "waveforms_test = []\n",
    "for i, file_name in enumerate(files_test):\n",
    "    if i % 100 == 0:\n",
    "        print 'Loaded testing waveform #' + str(i)\n",
    "    f = SAMPLES_FOLDER + file_name\n",
    "    waveforms_test.append(lr.load(f)[0])\n",
    "X_test = np.stack(waveforms_test)\n",
    "print X_test.shape\n",
    "\n",
    "\n",
    "waveforms_train = []\n",
    "for i, file_name in enumerate(files_train):\n",
    "    if i % 100 == 0:\n",
    "        print 'Loaded training waveform #' + str(i)\n",
    "    f = SAMPLES_FOLDER + file_name\n",
    "    waveforms_train.append(lr.load(f)[0])\n",
    "X_train = np.stack(waveforms_train)\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepares the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_test_mfcc = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    S = X_test[i,:]\n",
    "    mfcc = lr.feature.mfcc(y=S, sr=sampling_rate, hop_length=HOP_LENGTH, n_mfcc=N_MFCC)\n",
    "    L_test_mfcc.append(mfcc)\n",
    "X_test_mfcc = np.stack(L_test_mfcc)\n",
    "print X_test_mfcc.shape\n",
    "\n",
    "L_train_mfcc = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    S = X_train[i,:]\n",
    "    mfcc = lr.feature.mfcc(y=S, sr=sampling_rate, hop_length=HOP_LENGTH, n_mfcc=N_MFCC)\n",
    "    L_train_mfcc.append(mfcc)\n",
    "X_train_mfcc = np.stack(L_train_mfcc)\n",
    "print X_train_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "lr.display.specshow(X_train_mfcc[10,...], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mfcc = np.reshape(X_test_mfcc, (X_test_mfcc.shape[0],-1))\n",
    "X_train_mfcc = np.reshape(X_train_mfcc, (X_train_mfcc.shape[0],-1))\n",
    "print X_test_mfcc.shape\n",
    "print X_train_mfcc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "headers=['algo', 'type', 'param1','param2','regularization',\n",
    "         'target','metric', 'train_score', 'test_score']\n",
    "with open(RESULTS_FILE, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    \n",
    "def evaluate_algo(algo_label, grid_reg, grid_class):\n",
    "    results = []\n",
    "    for t_i, t_name in enumerate(list(Y_train)):\n",
    "\n",
    "        print 'predicting feature', t_name\n",
    "        y_train = Y_train[t_name]\n",
    "        y_test = Y_test[t_name]\n",
    "        print y_train.dtype\n",
    "        \n",
    "        if t_name in DEPENDENCIES:\n",
    "            switch = DEPENDENCIES[t_name]\n",
    "            \n",
    "            to_keep_train = (Y_train[switch] == 'on')\n",
    "            print 'Keeping', str(sum(to_keep_train)), 'training examples out of',  str(len(to_keep_train))\n",
    "            y_train = y_train[to_keep_train]\n",
    "            X_train= X_train_mfcc[to_keep_train,...]\n",
    "            \n",
    "            to_keep_test = (Y_test[switch] == 'on')\n",
    "            print 'Keeping', str(sum(to_keep_test)), 'training examples out of',  str(len(to_keep_test))\n",
    "            y_test = y_test[to_keep_test]\n",
    "            X_test = X_test_mfcc[to_keep_test,...]\n",
    "        \n",
    "        else:\n",
    "            X_train= X_train_mfcc\n",
    "            X_test= X_test_mfcc\n",
    "        \n",
    "        print X_train.shape, y_train.shape\n",
    "        print X_test.shape, y_test.shape\n",
    "        \n",
    "        best_params_C = None\n",
    "        best_params_R = None\n",
    "        \n",
    "        try:\n",
    "            # Case 1: classification\n",
    "            if y_train.dtype == 'object':\n",
    "\n",
    "                metric = 'class'\n",
    "\n",
    "                # Cross-Validation Score\n",
    "                grid_class.fit(X_train, y_train)\n",
    "                cross_val_scores = grid_class.best_score_\n",
    "                best_params_C = grid_class.best_params_\n",
    "                print cross_val_scores\n",
    "\n",
    "                # Test Score\n",
    "                test_pred = grid_class.predict(X_test)\n",
    "                test_score = accuracy_score(test_pred, y_test)\n",
    "                print test_score\n",
    "\n",
    "\n",
    "            # Case 2: regression\n",
    "            elif y_train.dtype == 'float64':\n",
    "\n",
    "                metric = 'reg'\n",
    "\n",
    "                # Cross-Validation Score\n",
    "                grid_reg.fit(X_train, y_train)\n",
    "                cross_val_scores = grid_reg.best_score_ * -1\n",
    "                best_params_R = grid_reg.best_params_\n",
    "                print cross_val_scores\n",
    "\n",
    "                # Test Score\n",
    "                test_pred = grid_reg.predict(X_test)\n",
    "                test_score = mean_absolute_error(test_pred, y_test)\n",
    "                print test_score\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Wrong Column Type')\n",
    "\n",
    "            out = (algo_label, 'per_output', best_params_R, best_params_C,None,\n",
    "                   t_name, metric, cross_val_scores, test_score)\n",
    "            print out\n",
    "            with open(RESULTS_FILE, 'a') as f:\n",
    "                writer = csv.writer(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                writer.writerow(out)\n",
    "\n",
    "        except:\n",
    "            print \"Unexpected error:\", sys.exc_info()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "algo_C =neighbors.KNeighborsClassifier()\n",
    "grid_C = GridSearchCV(algo_C, {\"n_neighbors\":[3,5,8,16]}, scoring='accuracy', verbose=2)\n",
    "\n",
    "algo_R =neighbors.KNeighborsRegressor()\n",
    "grid_R = GridSearchCV(algo_R, {\"n_neighbors\":[3,5,8,16]}, scoring='neg_mean_absolute_error', verbose=2)\n",
    "\n",
    "evaluate_algo('kNN', grid_R, grid_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "algo_C = tree.DecisionTreeClassifier()\n",
    "grid_C = GridSearchCV(algo_C, {\"max_depth\":[2,4,8,16,32,64,128]}, scoring='accuracy', verbose=2)\n",
    "\n",
    "algo_R = tree.DecisionTreeRegressor()\n",
    "grid_R = GridSearchCV(algo_R, {\"max_depth\":[2,4,8,16,32,64,128]}, scoring='neg_mean_absolute_error', verbose=2)\n",
    "\n",
    "evaluate_algo('Decision Tree', grid_R, grid_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import dummy\n",
    "\n",
    "algo_C = dummy.DummyClassifier()\n",
    "grid_C = GridSearchCV(algo_C, {\"strategy\":[\"most_frequent\"]}, scoring='accuracy', verbose=2)\n",
    "\n",
    "algo_R = dummy.DummyRegressor()\n",
    "grid_R = GridSearchCV(algo_R, {\"strategy\":[\"mean\"]}, scoring='neg_mean_absolute_error', verbose=2)\n",
    "\n",
    "evaluate_algo('Naive', grid_R, grid_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def target_info(df_y):\n",
    "    infos = collections.OrderedDict()\n",
    "    \n",
    "    for i,name in enumerate(list(df_y)):\n",
    "        print name\n",
    "        \n",
    "        y = df_y[[name]].values.flatten()\n",
    "        infos[name] = {'type':y.dtype}\n",
    "        \n",
    "        if y.dtype=='object':\n",
    "            u_vals = sorted(np.unique(y))\n",
    "            infos[name]['int2char'] = {i:v for i,v in enumerate(u_vals)}\n",
    "            infos[name]['char2int'] = {v:i for i,v in enumerate(u_vals)}\n",
    "            \n",
    "        elif y.dtype=='float64':\n",
    "            infos[name]['mean'] = np.mean(y)\n",
    "            infos[name]['sd'] = np.std(y)\n",
    "        \n",
    "    return infos\n",
    "\n",
    "# Gets target info\n",
    "Y_info = target_info(Y_train)\n",
    "print Y_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preps input data\n",
    "X_train_mfcc = X_train_mfcc.reshape([X_train_mfcc.shape[0],N_MFCC,-1]).transpose(0,2,1)\n",
    "X_test_mfcc = X_test_mfcc.reshape([X_test_mfcc.shape[0],N_MFCC,-1]).transpose(0,2,1)\n",
    "\n",
    "print ''\n",
    "print X_train_mfcc.shape\n",
    "print X_test_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def format_output(Y):\n",
    "    out = {}\n",
    "    for name,infos in Y_info.iteritems():\n",
    "\n",
    "        # Normalizes/one-hot encodes\n",
    "        if infos['type'] == 'float64':\n",
    "            y = (Y[name] - infos['mean']) / infos['sd']\n",
    "            \n",
    "        elif infos['type'] == 'object':\n",
    "            char2int = infos['char2int']\n",
    "            y = np.zeros((len(Y[name]), len(char2int)))\n",
    "            for i,yval in enumerate(Y[name]):\n",
    "                y[i, char2int[yval]] = 1        \n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "        # Sets to zero if necessary\n",
    "        if name in DEPENDENCIES:\n",
    "            switch = DEPENDENCIES[name]\n",
    "            is_off = Y[switch] == \"off\"\n",
    "            print 'Setting', str(sum(is_off)),'elements to zero'\n",
    "            y[is_off] = 0\n",
    "        \n",
    "        print name, y.shape\n",
    "        out[name] = y\n",
    "    \n",
    "    return out\n",
    "\n",
    "        \n",
    "def test_model(label, params1, params2, regul, model, X_train, X_test):\n",
    "    \n",
    "    try:\n",
    "        # Prepares input and output data\n",
    "        X_mean = np.mean(X_train, axis=(0))\n",
    "        X_sd = np.std(X_train, axis=(0))\n",
    "\n",
    "        X_train = (X_train - X_mean) / X_sd\n",
    "        X_test  = (X_test - X_mean) / X_sd\n",
    "\n",
    "        Y_dict_train = format_output(Y_train)\n",
    "        Y_dict_test  = format_output(Y_test)\n",
    "\n",
    "        # Trains the model\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "        hist = model.fit(X_train, Y_dict_train, \n",
    "                  epochs=N_EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE,\n",
    "                 validation_split = VALIDATION, callbacks=[early_stopping])\n",
    "\n",
    "        # Makes predictions\n",
    "        pred = model.predict(X_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "\n",
    "        # Gets validation and test scores (for each metric)\n",
    "        Y = {}\n",
    "        for j, Y_pred in enumerate(pred):\n",
    "            print 'Output:', j\n",
    "            t_name = Y_info.keys()[j]\n",
    "            t_infos = Y_info[t_name]\n",
    "            truth = Y_test[t_name]\n",
    "            print t_name\n",
    "            print Y_pred.shape\n",
    "\n",
    "            if t_name in DEPENDENCIES:\n",
    "                switch = DEPENDENCIES[t_name]\n",
    "\n",
    "                to_keep_test = (Y_test[switch] == 'on')\n",
    "                print 'Keeping', str(sum(to_keep_test)), 'training examples out of',  str(len(to_keep_test))\n",
    "                truth = truth[to_keep_test]\n",
    "                Y_pred = Y_pred[to_keep_test,...]\n",
    "                print Y_pred.shape, truth.shape\n",
    "\n",
    "            if t_infos['type'] == 'float64':\n",
    "                test_metric = 'reg'\n",
    "                Y_pred = Y_pred.flatten()\n",
    "                y_pred = Y_pred * t_infos['sd'] + t_infos['mean']\n",
    "                y_pred = y_pred.tolist()\n",
    "                test_score = mean_absolute_error(y_pred, truth)\n",
    "\n",
    "            elif t_infos['type'] == 'object':\n",
    "                test_metric = 'class'\n",
    "                y_i = np.argmax(Y_pred, axis=1)\n",
    "                y_pred = [t_infos['int2char'][y] for y in y_i]\n",
    "                test_score = accuracy_score(y_pred, truth)\n",
    "\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "            train_scores = -1 * hist.history['val_loss'][-1]\n",
    "            out = (label, 'joint', params1, params2, regul,\n",
    "                   t_name, test_metric, train_scores, test_score)\n",
    "            print out\n",
    "            with open(RESULTS_FILE, 'a') as f:\n",
    "                writer = csv.writer(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                writer.writerow(out)\n",
    "\n",
    "            Y[t_name] = y_pred\n",
    "            \n",
    "    except:\n",
    "        print \"Unexpected error:\", sys.exc_info()[0]\n",
    "        return\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_output(h_layer):\n",
    "    # Output layers and losses\n",
    "    out_layers = []\n",
    "    losses = {}\n",
    "    metrics = {}\n",
    "    \n",
    "    # Adds on/off switches\n",
    "    switches = []\n",
    "    for name,infos in Y_info.iteritems():\n",
    "        if not name in DEPENDENCIES and infos['type'] == 'object':\n",
    "            out_dim = len(infos['char2int'])\n",
    "            out_layer = Dense(out_dim, activation='softmax', name=name)(h_layer)\n",
    "            losses[name] = 'categorical_crossentropy'\n",
    "            metrics[name] = 'accuracy'\n",
    "            switches.append(name)\n",
    "            out_layers.append(out_layer)\n",
    "            \n",
    "        if not name in DEPENDENCIES and infos['type'] == 'float64':\n",
    "            out_layer = Dense(1, name=name)(h_layer)\n",
    "            losses[name] = 'mean_absolute_error'\n",
    "            metrics[name] = 'mean_absolute_error'\n",
    "            switches.append(name)\n",
    "            out_layers.append(out_layer)\n",
    "            \n",
    "    # Adds dependent switches and knobs\n",
    "    dependent = []\n",
    "    for name,infos in Y_info.iteritems():\n",
    "        \n",
    "        if name in DEPENDENCIES and infos['type'] == 'float64':\n",
    "            pred_layer = Dense(1)(h_layer)\n",
    "            \n",
    "            switch = DEPENDENCIES[name]\n",
    "            li_switch = switches.index(switch)\n",
    "            i_on = Y_info[switch]['char2int']['on']\n",
    "            switch = Lambda(lambda T: T[:,i_on])(out_layers[li_switch])\n",
    "            out_layer = Multiply(name = name)([pred_layer, switch])\n",
    "            \n",
    "            losses[name] = 'mean_absolute_error'\n",
    "            metrics[name] = 'mean_absolute_error'\n",
    "            out_layers.append(out_layer)\n",
    "            dependent.append(name)\n",
    "\n",
    "        \n",
    "        if name in DEPENDENCIES and infos['type'] == 'object':\n",
    "            out_dim = len(infos['char2int'])\n",
    "            pred_layer = Dense(out_dim, activation='softmax')(h_layer)            \n",
    "            \n",
    "            switch = DEPENDENCIES[name]\n",
    "            li_switch = switches.index(switch)\n",
    "            i_on = Y_info[switch]['char2int']['on']\n",
    "            switch = Lambda(lambda T: T[:,i_on])(out_layers[li_switch])\n",
    "            out_layer = Multiply(name = name)([pred_layer, switch])\n",
    "            \n",
    "            losses[name] = 'categorical_crossentropy'\n",
    "            metrics[name] = 'accuracy'\n",
    "            out_layers.append(out_layer)\n",
    "            dependent.append(name)\n",
    "        \n",
    "    # Reorders everything\n",
    "    all_out = switches + dependent\n",
    "    ord_out = []\n",
    "    for out_name in Y_info:\n",
    "        o = out_layers[all_out.index(out_name)]\n",
    "        ord_out.append(o)\n",
    "\n",
    "    return ord_out, metrics, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: 1 layer perceptron\n",
    "from keras.layers import Input, Dense, Flatten, Multiply, Lambda, RepeatVector\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "def MLP(n_hidden_units, n_layers, regul, in_shape):\n",
    "    # Input layer\n",
    "    in_layer = Input(shape=in_shape)\n",
    "    \n",
    "    # Hidden layers\n",
    "    h_layer = Flatten()(in_layer)\n",
    "    for i in range(n_layers):\n",
    "        h_layer = Dense(n_hidden_units, activation='relu')(h_layer)\n",
    "\n",
    "    out_layers, metrics, losses = NN_output(h_layer)\n",
    "    model = Model(inputs = in_layer, outputs = out_layers)\n",
    "    model.compile(loss=losses, optimizer='adam')\n",
    "    \n",
    "    print model.summary()\n",
    "    return model\n",
    "\n",
    "for N_LAYERS in [1,2]:\n",
    "    for N_UNITS in [64,90,128]:\n",
    "        for REGUL in [0]:\n",
    "            in_dim = X_train_mfcc.shape[1:]\n",
    "            model = MLP(N_UNITS, N_LAYERS, REGUL, in_dim)\n",
    "            out = test_model('MLP', N_UNITS, N_LAYERS, REGUL, model, X_train_mfcc, X_test_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "def modLSTM(n_hidden_units, n_layers, regul, in_shape):\n",
    "    # Input layer\n",
    "    in_layer = Input(shape=in_shape)\n",
    "    \n",
    "    # Hidden layers\n",
    "    h_layer = in_layer\n",
    "    for i in range(n_layers):\n",
    "        seq = i < n_layers - 1\n",
    "        h_layer = LSTM(n_hidden_units, return_sequences=seq, dropout=regul)(h_layer)\n",
    "        \n",
    "    # Output layers and losses\n",
    "    out_layers, metrics, losses = NN_output(h_layer)\n",
    "    model = Model(inputs = in_layer, outputs = out_layers)\n",
    "    model.compile(loss=losses, optimizer='adam')\n",
    "    \n",
    "    print model.summary()\n",
    "    return model\n",
    "\n",
    "for N_LAYERS in [1,2]:\n",
    "    for N_UNITS in [32,64,80,128]:\n",
    "        for REGUL in [0,0.2]:\n",
    "            in_dim = X_train_mfcc.shape[1:]\n",
    "            model = modLSTM(N_UNITS, N_LAYERS, REGUL, in_dim)\n",
    "            out = test_model('LSTM', N_UNITS, N_LAYERS, REGUL, model, X_train_mfcc, X_test_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D,MaxPooling1D,GlobalMaxPooling1D\n",
    "\n",
    "W = 4\n",
    "\n",
    "def modConvo(n_filters, n_layers, regul, in_shape):\n",
    "    # Input layer\n",
    "    print in_shape\n",
    "    in_layer = Input(shape=in_shape)\n",
    "    \n",
    "    # Hidden layers\n",
    "    h_layer = in_layer\n",
    "    for i in range(n_layers):\n",
    "        print i\n",
    "        conv_layer = Conv1D(n_filters*(i+1), W, \n",
    "                          kernel_regularizer=regularizers.l2(regul))(h_layer)\n",
    "        h_layer = MaxPooling1D(W, strides=2)(conv_layer)\n",
    "    \n",
    "    h_layer_pool = GlobalMaxPooling1D()(h_layer)\n",
    "    h_layer_full = Dense(n_filters, \n",
    "                          kernel_regularizer=regularizers.l2(regul))(h_layer_pool)\n",
    "    \n",
    "    # Output layers and losses\n",
    "    out_layers, metrics, losses = NN_output(h_layer_full)\n",
    "    model = Model(inputs = in_layer, outputs = out_layers)\n",
    "    model.compile(loss=losses, optimizer='adam')\n",
    "    \n",
    "    print model.summary()\n",
    "    return model\n",
    "\n",
    "for N_FILTERS in [16,32,48,64]:\n",
    "    for N_LAYERS in [1,2]:\n",
    "        for REGUL in [0]:\n",
    "            in_dim = X_train_mfcc.shape[1:]\n",
    "            model = modConvo(N_FILTERS, N_LAYERS, REGUL, in_dim)\n",
    "            out = test_model('Conv', N_FILTERS, N_LAYERS, REGUL, model, X_train_mfcc, X_test_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mid level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def target_info(df_y):\n",
    "    infos = collections.OrderedDict()\n",
    "    \n",
    "    for i,name in enumerate(list(df_y)):\n",
    "        print name\n",
    "        \n",
    "        y = df_y[[name]].values.flatten()\n",
    "        infos[name] = {'type':y.dtype}\n",
    "        \n",
    "        if y.dtype=='object':\n",
    "            u_vals = sorted(np.unique(y))\n",
    "            infos[name]['int2char'] = {i:v for i,v in enumerate(u_vals)}\n",
    "            infos[name]['char2int'] = {v:i for i,v in enumerate(u_vals)}\n",
    "            \n",
    "        elif y.dtype=='float64':\n",
    "            infos[name]['mean'] = np.mean(y)\n",
    "            infos[name]['sd'] = np.std(y)\n",
    "        \n",
    "    return infos\n",
    "\n",
    "# Gets target info\n",
    "Y_info = target_info(Y_train)\n",
    "print Y_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_test_mel = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    S = X_test[i,:]\n",
    "    mel = lr.feature.melspectrogram(y=S, sr=sampling_rate, hop_length=HOP_LENGTH, n_mels=N_MEL)\n",
    "    L_test_mel.append(mel)\n",
    "X_test_mel = np.stack(L_test_mel)\n",
    "print X_test_mel.shape\n",
    "\n",
    "L_train_mel = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    S = X_train[i,:]\n",
    "    mel = lr.feature.melspectrogram(y=S, sr=sampling_rate, hop_length=HOP_LENGTH, n_mels=N_MEL)\n",
    "    L_train_mel.append(mel)\n",
    "X_train_mel = np.stack(L_train_mel)\n",
    "print X_train_mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "lr.display.specshow(X_train_mel[1,...], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mel = np.transpose(X_train_mel, (0,2,1))\n",
    "X_test_mel = np.transpose(X_test_mel, (0,2,1))\n",
    "print X_train_mel.shape, X_test_mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N_LAYERS in [1,2]:\n",
    "    for N_UNITS in [64,90,128]:\n",
    "        for REGUL in [0]:\n",
    "            in_dim = X_train_mel.shape[1:]\n",
    "            model = MLP(N_UNITS, N_LAYERS, REGUL, in_dim)\n",
    "            out = test_model('MLP_mid', N_UNITS, N_LAYERS, REGUL, model, X_train_mel, X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N_LAYERS in [1,2]:\n",
    "    for N_UNITS in [32,64,80,128]:\n",
    "        for REGUL in [0,0.2]:\n",
    "            in_dim = X_train_mel.shape[1:]\n",
    "            model = modLSTM(N_UNITS, N_LAYERS, REGUL, in_dim)\n",
    "            out = test_model('LSTM_mid', N_UNITS, N_LAYERS, REGUL, model, X_train_mel, X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N_FILTERS in [16,32,48,64]:\n",
    "    for N_LAYERS in [1,2]:\n",
    "        for REGUL in [0]:\n",
    "            in_dim = X_train_mel.shape[1:]\n",
    "            model = modConvo(N_FILTERS, N_LAYERS, REGUL, in_dim)\n",
    "            out = test_model('Conv_mid', N_FILTERS, N_LAYERS, REGUL, model, X_train_mel, X_test_mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i RESULTS_FILE\n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "# Processing\n",
    "csv <- read.csv(RESULTS_FILE)\n",
    "\n",
    "indep_models <- csv %>% filter(type == 'per_output')\n",
    "\n",
    "joint_models <- csv %>% filter(type == 'joint')\n",
    "to_keep <- joint_models %>% \n",
    "                group_by(algo, type, param1,param2,regularization) %>%\n",
    "                summarize(train_score = mean(train_score)) %>%\n",
    "                group_by(algo) %>%\n",
    "                filter(train_score == max(train_score)) %>% data.frame()\n",
    "print(to_keep)\n",
    "\n",
    "joint_models <- semi_join(joint_models, to_keep, by=c(\"algo\",\"param1\",\"param1\",\"regularization\")) %>%\n",
    "                distinct()\n",
    "\n",
    "all_models <- rbind(indep_models, joint_models)\n",
    "\n",
    "# Plotting\n",
    "to_plot <- all_models %>%\n",
    "            select(algo, metric, test_score) %>%\n",
    "            group_by(algo, metric) %>%\n",
    "            summarize(score = mean(test_score)) %>%\n",
    "            as.data.frame\n",
    "print(to_plot)\n",
    "\n",
    "to_plot$metric <- factor(to_plot$metric)\n",
    "\n",
    "p <- ggplot(to_plot, aes(x=factor(algo), y=score)) +\n",
    "    geom_bar(stat='identity') +\n",
    "    facet_grid(metric~., scales='free')\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: -- \u001b[1mAttaching packages\u001b[22m --------------------------------------- tidyverse 1.2.1 --\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: \u001b[32m<U+221A>\u001b[39m \u001b[34mggplot2\u001b[39m 2.2.1     \u001b[32m<U+221A>\u001b[39m \u001b[34mpurrr  \u001b[39m 0.2.4\n",
      "\u001b[32m<U+221A>\u001b[39m \u001b[34mtibble \u001b[39m 1.4.1     \u001b[32m<U+221A>\u001b[39m \u001b[34mdplyr  \u001b[39m 0.7.4\n",
      "\u001b[32m<U+221A>\u001b[39m \u001b[34mtidyr  \u001b[39m 0.7.2     \u001b[32m<U+221A>\u001b[39m \u001b[34mstringr\u001b[39m 1.2.0\n",
      "\u001b[32m<U+221A>\u001b[39m \u001b[34mreadr  \u001b[39m 1.1.1     \u001b[32m<U+221A>\u001b[39m \u001b[34mforcats\u001b[39m 0.2.0\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: -- \u001b[1mConflicts\u001b[22m ------------------------------------------ tidyverse_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/thib/.virtualenvs/keras/local/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: Saving 10 x 6.67 in image\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      algo  type param1 param2 regularization train_score\n",
       "1     Conv joint     64      2            0.0   -13.55755\n",
       "2 Conv_mid joint     16      1            0.0   -15.66745\n",
       "3     LSTM joint    128      2            0.2   -13.08998\n",
       "4 LSTM_mid joint     80      2            0.2   -14.91300\n",
       "5      MLP joint    128      2            0.0   -13.51242\n",
       "6  MLP_mid joint     64      2            0.0   -15.19052\n",
       "            algo metric     score                     family\n",
       "1           Conv  class 0.4479167         joint model + MFCC\n",
       "2           Conv    reg 2.1559831         joint model + MFCC\n",
       "3       Conv_mid  class 0.2518333 joint model + Mel Spectrum\n",
       "4       Conv_mid    reg 2.4841223 joint model + Mel Spectrum\n",
       "5  Decision Tree  class 0.4008333         Independent + MFCC\n",
       "6  Decision Tree    reg 2.1478555         Independent + MFCC\n",
       "7            kNN  class 0.3555000         Independent + MFCC\n",
       "8            kNN    reg 2.1473486         Independent + MFCC\n",
       "9           LSTM  class 0.4771667         joint model + MFCC\n",
       "10          LSTM    reg 2.0887280         joint model + MFCC\n",
       "11      LSTM_mid  class 0.2733333 joint model + Mel Spectrum\n",
       "12      LSTM_mid    reg 2.3523489 joint model + Mel Spectrum\n",
       "13           MLP  class 0.4677500         joint model + MFCC\n",
       "14           MLP    reg 2.1646721         joint model + MFCC\n",
       "15       MLP_mid  class 0.2863333 joint model + Mel Spectrum\n",
       "16       MLP_mid    reg 2.4342762 joint model + Mel Spectrum\n",
       "17         Naive  class 0.2340000         Independent + MFCC\n",
       "18         Naive    reg 2.5148461         Independent + MFCC\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R \n",
    "\n",
    "RESULTS_FILE <- \"RESULTS-noisemaker-2018-01-10_15:47.csv\"\n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "# Processing\n",
    "csv <- read.csv(RESULTS_FILE)\n",
    "\n",
    "indep_models <- csv %>% filter(type == 'per_output')\n",
    "\n",
    "joint_models <- csv %>% filter(type == 'joint')\n",
    "to_keep <- joint_models %>% \n",
    "                group_by(algo, type, param1,param2,regularization) %>%\n",
    "                summarize(train_score = mean(train_score)) %>%\n",
    "                group_by(algo) %>%\n",
    "                filter(train_score == max(train_score)) %>% data.frame()\n",
    "print(to_keep)\n",
    "\n",
    "joint_models <- semi_join(joint_models, to_keep, by=c(\"algo\",\"param1\",\"param1\",\"regularization\")) %>%\n",
    "                distinct()\n",
    "\n",
    "all_models <- rbind(indep_models, joint_models)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "to_plot <- all_models %>%\n",
    "            select(algo, metric, test_score) %>%\n",
    "            group_by(algo, metric) %>%\n",
    "            summarize(score = mean(test_score)) %>%\n",
    "            as.data.frame\n",
    "to_plot$family <- sapply(to_plot$algo,function(n){\n",
    "    if (n%in%c('Conv', \"LSTM\", \"MLP\")){\n",
    "        \"joint model + MFCC\"\n",
    "    } else if (n%in%c('Conv_mid', \"LSTM_mid\", \"MLP_mid\")){\n",
    "        \"joint model + Mel Spectrum\"\n",
    "    } else{\n",
    "        \"Independent + MFCC\"\n",
    "    }\n",
    "})\n",
    "\n",
    "print(to_plot)\n",
    "\n",
    "to_plot$metric <- factor(to_plot$metric)\n",
    "\n",
    "p <- ggplot(to_plot, aes(x=factor(algo), y=score, color=family, fill=family)) +\n",
    "    geom_bar(stat='identity') +\n",
    "    facet_grid(metric~family, scales='free')\n",
    "print(p)\n",
    "\n",
    "ggsave('results_guitar.pdf', p, width=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
